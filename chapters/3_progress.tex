\chapter{Progress of the Project and Nextn Steps} % 1000
Most of the work on this project this far has been on understanding the underlying mathematics underpinning interactive proofs, quantum computing, quantum learning, and classical verification via cryptographic methods. However, we identified that the most important focus for implementation so far would be to implement the MoS model from Caro et al. \cite{https://doi.org/10.4230/lipics.itcs.2024.24}. Whilst this is the case, we try to draw links to Mahadev's works \cite{mahadev2023classicalverificationquantumcomputations}, and outline some next steps to progress forwards throughout the next term.
\section{Implementing Mixture of Superpositions}
There are numerous subtle details in the implementation Caro et al. provide in their paper, of which made it harder to implement in practice and that I had to overcome as obstacles when writing code as to keep complication to a minimum. At the point of writing, this is an incomplete and not vigorously tested implementation, although this is definitely a next step upon further discussion with my supervisor.

We can begin by referring to the paper definition of a mixture-of-superposition state. Given $\mathcal{D}$ with a uniform marginal on $x \in \{0, 1\}$, we defined an unknown conditional label expectation $\varphi: \{0, 1\}^n \to [0, 1]$. This by definition is equivalent to $\mathbb{P}[y = 1 | x]$. We then, in the distributional-agnostic setting sample a random boolean function $f: \{0, 1\}^n \to \{0, 1\}$ by independent per-point draws such that $f(x) \sim \text{Bernoulli}(\phi(x))$.

The Caro et al. paper \cite{https://doi.org/10.4230/lipics.itcs.2024.24} in Definition 8 states:
\begin{equation}
	\begin{split}
		\mathbb{P}_{f \sim F_\mathcal{D}}[f = \tilde{f}] & = \prod_{z \in \mathcal{X}_n} \mathbb{P}_{(x, y) \sim \mathcal{D}} [\tilde{f}(z) = y | x = z]        \\
		                                                 & = \prod_{z \in \mathcal{X}_n} \left((1 - \varphi(z))(1-\tilde{f}(z)) + \varphi(z)\tilde{f}(z)\right)
	\end{split}
\end{equation}
Which exactly describes independent Bernoulli draws for each $x$. I implement that as follows:
% \begin{NoIndent}
\begin{mintedbox}{python}
def sample_f(self, rng: Optional[Generator] = None) -> np.ndarray:
    """
    Sample a random Boolean function f ~ F_D.

    For each x in {0,1}^n, independently sample f(x) ~ Bernoulli(phi(x)).

    Returns
    -------
    f : np.ndarray of shape (2^n,), dtype=np.uint8
    f[x] is the value f(x) in {0, 1}.
    """
    if rng is None:
        rng = self.rng
    return (rng.random(self.dim_x) < self._phi).astype(np.uint8)
\end{mintedbox}
% \end{NoIndent}

In other words, the code performs an independent Bernoulli trial for every truth table entry for every combination of boolean input strings of size \texttt{self.dim\_x}. For a fixed $f$, the paper defines the pure quantum example state: 
\begin{equation}
  \ket{\phi_{(\mathcal{U}_n, f})} = \frac{1}{\sqrt{2^n}}\sum_{x \in \{0, 1\}} \ket{x, f(x)}
\end{equation}

And the MoS example is the mixed state:
\begin{equation}
  \rho_\mathcal{D} = \mathbb{E}_{f \sim F_\mathcal{D}}\left[\ket{\phi_{(\mathcal{U}_n, f)}}\bra{\phi_{(\mathcal{U}_n, f)}}\right]
\end{equation}

The simulator, instead of explicitly building $\rho_\mathcal{D}$ every time, for each "shot"/sample we sample $f \sim F_\mathcal{D}$ and prepares the pure state:
% \begin{NoIndent}
\begin{mintedbox}
def statevector_from_f(self, f: np.ndarray) -> Statevector:
    """
    Construct the Qiskit Statevector |phi_(U_n, f)> for a fixed function f.
    
    |phi_(U_n, f)> = (1/sqrt(2^n)) * sum_x |x, f(x)>
    """
    sv_data = np.zeros(self.dim_total, dtype=np.complex128)
    amp = 1.0 / np.sqrt(self.dim_x)
    
    for x in range(self.dim_x):
        idx = x + int(f[x]) * self.dim_x
        sv_data[idx] = amp
    
    return Statevector(sv_data)
\end{mintedbox}
% \end{NoIndent}

To actually simulate the building of the circuit, we need state that correctly maps inputs to function outputs using multi-controlled X gates:
% \begin{NoIndent}
\begin{mintedbox}{python}
def circuit_oracle_f(self, f: np.ndarray) -> QuantumCircuit:
    """
    Build an oracle circuit U_f that maps |x>|0> -> |x>|f(x)>.
    
    This implements the standard phase-free oracle using multi-controlled X gates.
    For each x where f(x)=1, flip the target qubit conditioned on input being x.
    
    Parameters
    ----------
    f : np.ndarray
        The Boolean function values.
    
    Returns
    -------
    qc : QuantumCircuit
        Oracle circuit on n+1 qubits.
    """
    qr = QuantumRegister(self.n + 1, 'q')
    qc = QuantumCircuit(qr, name='oracle_f')
    
    # For each x where f(x) = 1, apply MCX controlled on |x>
    for x in range(self.dim_x):
        if f[x] == 1:
            # Determine which qubits need X gates (for 0 bits in x)
            ctrl_state = format(x, f'0{self.n}b')[::-1]  # reversed for Qiskit ordering
            
            if self.n == 0:
                qc.x(qr[0])
            else:
                qc.mcx(
                    control_qubits=list(range(self.n)),
                    target_qubit=self.n,
                    ctrl_state=ctrl_state
                )
    
    return qc
\end{mintedbox}
% \end{NoIndent}
At this point, it would be correct to say that this only works on discrete function examples, but in the code, we actully average over many sampled $f$. An important clarification I had to make myself at this point was that MoS is not a model for learning, but a model for access - and the learning happens after the MoS samples are classically post-processed. This is followed by a hadamard unitary gate operation on all $n + 1$ qubits.

The MoS construction pushes the concept of noise in distributional-agnostic learning into the mixture over $f$ by sampling clean labellings and averaging over them. Caro et al.'s paper \cite{https://doi.org/10.4230/lipics.itcs.2024.24} shows that this procedure results in sampling strings from $\{0, 1\}$ according to the distribution:

\begin{equation}
  \mathbb{P}(s) = \frac{1}{2^n}\left(1 - \mathbb{E}_{x \sim \mathcal{U}_n}[(\phi(x))^2]\right) + (\hat{\phi}(x))^2
\end{equation}

Now, the classical post processing can only recieve the classical string outputs from the above measurements. We identify (statistically) frequent $s$ values, and treat those $s$'s as candidate parities and picks the best such parity to maximise:
\begin{equation}
  \hat{\phi}(s) = \mathbb{E}_{(x, y) \sim \mathcal{D}}\left[(-1)^y(-1)^{s \cdot x}\right]
\end{equation}

In this simulation, our generator for $f$ indeed knows the function $\phi$, but we use the generator as an oracle used to simulate the world, not something that the prover or verifier has explicit access to, however both the prover and verifier are allowed to sample from the distribution. 

\subsection{Next steps}
The immediate priority for the simulation work is to move beyond sampling idealised MoS examples in isolation and instead implement an explicit interaction between a classical verifier and a quantum prover. At present, the simulator effectively plays the role of an omniscient environment that samples $f\sim F_{\mathcal{D}}$ and prepares the corresponding example state internally. A more faithful model would separate these roles. The prover could prepare MoS samples using only oracle access to $\mathcal{D}$, while the verifier interacts with the prover solely through classical queries and measurement outcomes.

Concretely, this suggests implementing a protocol-level simulator in which the verifier adaptively requests samples, applies classical post-processing to the observed outcomes, and makes accept/reject or learning decisions based on empirical statistics. This would allow systematic testing of finite-sample behaviour, robustness to noise, and the sensitivity of the learning signal to deviations from the ideal MoS distribution. Such an implementation would also clarify which parts of the MoS procedure are essential for learning and which are artefacts of the idealised analysis, thereby informing later attempts at verification.

\section{Improvements and adjustments to Mahadev-style verification}
A natural point of contact between Mahadev-style classical verification and the MoS concept of Caro et al.\ is that the MoS procedure ultimately relies on a certified Hadamard-basis measurement. In the approximate Fourier sampling protocol, an $(n+1)$-qubit example state is prepared, a global Hadamard $H^{\otimes(n+1)}$ is applied, and the system is measured in the computational basis. Mahadev's measurement protocol is explicitly designed to certify such measurements: after a commitment using a noisy trapdoor claw-free (TCF) function family, the verifier can recover the outcome of an honest Hadamard measurement from the prover’s reported bit using trapdoor information. This observation motivates an attempt to reuse Mahadev’s machinery to certify the measurement stage of the MoS protocol, rather than the full quantum computation.

The concrete direction explored was to extend the single-qubit correction mechanism in Mahadev’s protocol to the $(n+1)$-qubit setting relevant for MoS-based Fourier sampling. The learning signal of interest is governed by the Fourier coefficients
\[
\hat{\phi}(s)=\mathbb{E}_{(x,y)\sim\mathcal{D}}\left[(-1)^y(-1)^{s\cdot x}\right],
\]
and Caro et al.\ show that, conditioned on the last qubit measuring $1$, the Hadamard-measurement outcomes on the remaining $n$ qubits approximately follow the squared Fourier spectrum $(\hat{\phi}(s))^2$. The attempted verification strategy was therefore to use Mahadev-style commitments to enforce honest Hadamard-basis measurements, while supplementing this with occasional computational-basis rounds intended to constrain the prover’s state to be close to a valid MoS example. For a fixed Boolean function $f$, the ideal pure state has the form
\[
\ket{\phi_{(\mathcal{U}_n,f)}}=2^{-n/2}\sum_{x\in\{0,1\}^n}\ket{x}\ket{f(x)},
\]
suggesting a possible spot-check approach where openings in the computational basis test consistency between the input and label registers.

This line of attack, however, runs into significant difficulties that prevented a complete protocol from being obtained. The central obstacle is that the MoS model is intrinsically mixed: each quantum example corresponds to an independently sampled $f\sim F_{\mathcal{D}}$, so there is no single deterministic function against which the verifier can consistently test computational-basis openings across rounds. As a result, naive spot-checking risks either implicitly conditioning on an $f$ not available to the verifier or disrupting the intended mixture structure. Also, when attempting to apply Mahadev’s correction procedure across multiple qubits, the induced Pauli one-time pads become correlated across the register, and relating the corrected outcomes to the joint distribution required for approximate Fourier sampling appears nontrivial. While the conceptual alignment between MoS sampling and certified Hadamard measurements is clear, translating this into a full verification protocol with rigorous completeness and soundness guarantees remains unresolved, and likely requires either a more refined multi-qubit measurement protocol or a weaker verification notion that targets the classical learning outcome rather than the exact quantum sampling distribution.

\subsection{Next steps}
On the verification side, the focus should primarily shift to theory, with the goal of isolating a verification target that is both meaningful for learning and compatible with Mahadev-style techniques. Rather than attempting to certify the full MoS sampling distribution, a promising direction is to define a weaker notion of correctness that only constrains the classical learning outcome, such as the identification of large Fourier coefficients or approximate parity structure, while tolerating deviations at the level of the underlying quantum state. Formalising such a notion could substantially reduce the burden on the verifier and avoid the intrinsic obstacles posed by the mixture over functions.

In parallel, there are limited but potentially informative avenues for practical exploration. One is to study small-scale, multi-qubit extensions of Mahadev’s measurement protocol in simulation to better understand where the current proof techniques break down. Another is to investigate hybrid protocols where only a subset of qubits (for example, the label qubit or a small number of randomly chosen data qubits) are subject to certified Hadamard measurements, while the remainder are treated as unverified. Although such approaches may not yield full completeness and soundness as Mahadev demonstrates in her original work, they could provide evidence for intermediate models that are both implementable and theoretically analysable, and help guide the development of a principled verification framework tailored to MoS-based learning.
